{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5cc3f03-8c4c-4894-a039-1e02ab14d42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3140745c-2e6b-4968-8c32-f87d95007f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5cc024f-f9dc-4535-acb0-fbe66cb201c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load a CSV file\n",
    "def load_csv(file_path):\n",
    "    \"\"\"\n",
    "    Load a CSV file into a Pandas DataFrame.\n",
    "    Args:\n",
    "        file_path (str): Path to the CSV file.\n",
    "    Returns:\n",
    "        pd.DataFrame: Loaded DataFrame.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"Successfully loaded: {file_path}\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading file {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to clean data\n",
    "def clean_data(df, file_name):\n",
    "    \"\"\"\n",
    "    Clean the dataset by handling missing values and removing irrelevant rows.\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame.\n",
    "        file_name (str): Name of the file being cleaned.\n",
    "    Returns:\n",
    "        pd.DataFrame: Cleaned DataFrame.\n",
    "    \"\"\"\n",
    "    if df is None:\n",
    "        print(f\"No data to clean in {file_name}.\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        if file_name == \"USER_LOG\":\n",
    "            df = df.dropna(subset=[\"Date\", \"Time\"])\n",
    "        elif file_name == \"ACTIVITY_LOG\":\n",
    "            df = df.dropna(subset=[\"Component\", \"Action\"])\n",
    "            df = df[~df[\"Component\"].isin([\"System\", \"Folder\"])]\n",
    "        elif file_name == \"COMPONENT_CODES\":\n",
    "            df = df.dropna(subset=[\"Component\", \"Code\"])\n",
    "        print(f\"Data cleaning successful for {file_name}.\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error during cleaning for {file_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to rename columns\n",
    "def rename_columns(df, file_name):\n",
    "    \"\"\"\n",
    "    Rename columns in the DataFrame.\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame.\n",
    "        file_name (str): Name of the file being processed.\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with renamed columns.\n",
    "    \"\"\"\n",
    "    if \"User Full Name *Anonymized\" in df.columns:\n",
    "        df.rename(columns={\"User Full Name *Anonymized\": \"User_ID\"}, inplace=True)\n",
    "        print(f\"Columns renamed for {file_name}.\")\n",
    "    return df\n",
    "\n",
    "# Function to merge data\n",
    "def merge_data(activity_log, user_log):\n",
    "    \"\"\"\n",
    "    Merge activity log with user log for user interaction analysis.\n",
    "    Args:\n",
    "        activity_log (pd.DataFrame): Cleaned ACTIVITY_LOG DataFrame.\n",
    "        user_log (pd.DataFrame): Cleaned USER_LOG DataFrame.\n",
    "    Returns:\n",
    "        pd.DataFrame: Merged DataFrame.\n",
    "    \"\"\"\n",
    "    merged_df = pd.merge(activity_log, user_log, on=\"User_ID\", how=\"inner\")\n",
    "    print(\"Data merged successfully.\")\n",
    "    return merged_df\n",
    "\n",
    "# Function to reshape data\n",
    "def reshape_data(df):\n",
    "    \"\"\"\n",
    "    Reshape the data using a pivot operation.\n",
    "    Args:\n",
    "        df (pd.DataFrame): Merged DataFrame.\n",
    "    Returns:\n",
    "        pd.DataFrame: Pivoted DataFrame.\n",
    "    \"\"\"\n",
    "    df[\"Month\"] = pd.to_datetime(df[\"Date\"]).dt.to_period(\"M\")\n",
    "    pivot_df = df.pivot_table(index=\"User_ID\", columns=\"Component\", values=\"Action\", aggfunc=\"count\", fill_value=0)\n",
    "    print(\"Data reshaped successfully.\")\n",
    "    return pivot_df\n",
    "\n",
    "# Function to calculate statistics\n",
    "def calculate_statistics(df, components):\n",
    "    \"\"\"\n",
    "    Calculate mean, mode, and median for specific components.\n",
    "    Args:\n",
    "        df (pd.DataFrame): Merged DataFrame.\n",
    "        components (list): List of components to calculate statistics for.\n",
    "    Returns:\n",
    "        dict: Dictionary containing statistics.\n",
    "    \"\"\"\n",
    "    stats = {}\n",
    "    for component in components:\n",
    "        if component in df.columns:\n",
    "            stats[component] = {\n",
    "                \"mean\": df[component].mean(),\n",
    "                \"mode\": df[component].mode().iloc[0],\n",
    "                \"median\": df[component].median(),\n",
    "            }\n",
    "    print(\"Statistics calculated.\")\n",
    "    return stats\n",
    "\n",
    "# Function to plot correlation\n",
    "def plot_correlation(df, components):\n",
    "    \"\"\"\n",
    "    Plot a correlation heatmap for specific components.\n",
    "    Args:\n",
    "        df (pd.DataFrame): Merged DataFrame.\n",
    "        components (list): List of components to analyze.\n",
    "    \"\"\"\n",
    "    correlation_df = df[components]\n",
    "    correlation_matrix = correlation_df.corr()\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "    plt.title(\"Correlation between Components\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44ad5590-7103-4a46-ac18-9e6208ba7ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded: USER_LOG.csv\n",
      "Data cleaning successful for USER_LOG.\n",
      "Columns renamed for USER_LOG.\n",
      "Successfully loaded: ACTIVITY_LOG.csv\n",
      "Data cleaning successful for ACTIVITY_LOG.\n",
      "Columns renamed for ACTIVITY_LOG.\n",
      "Successfully loaded: COMPONENT_CODES.csv\n",
      "Data cleaning successful for COMPONENT_CODES.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "file_paths = {\n",
    "    \"USER_LOG\": \"USER_LOG.csv\",\n",
    "    \"ACTIVITY_LOG\": \"ACTIVITY_LOG.csv\",\n",
    "    \"COMPONENT_CODES\": \"COMPONENT_CODES.csv\",\n",
    "}\n",
    "\n",
    "# Load and clean individual files\n",
    "user_log_df = load_csv(file_paths[\"USER_LOG\"])\n",
    "user_log_df = clean_data(user_log_df, \"USER_LOG\")\n",
    "user_log_df = rename_columns(user_log_df, \"USER_LOG\")\n",
    "\n",
    "activity_log_df = load_csv(file_paths[\"ACTIVITY_LOG\"])\n",
    "activity_log_df = clean_data(activity_log_df, \"ACTIVITY_LOG\")\n",
    "activity_log_df = rename_columns(activity_log_df, \"ACTIVITY_LOG\")\n",
    "\n",
    "component_codes_df = load_csv(file_paths[\"COMPONENT_CODES\"])\n",
    "component_codes_df = clean_data(component_codes_df, \"COMPONENT_CODES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54bcc6df-1d81-41ba-8d7b-2c7564d9b85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Date', 'Time', 'User_ID'], dtype='object')\n",
      "Index(['User_ID', 'Component', 'Action', 'Target'], dtype='object')\n",
      "Index(['Component', 'Code'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(user_log_df.columns)\n",
    "print(activity_log_df.columns)\n",
    "print(component_codes_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d43c3dea-5987-4c42-8e88-d60d7cd8c07d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((145262, 4), (150835, 3))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activity_log_df.shape, user_log_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fbc9ad7-239d-4541-8432-0279c388bd04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User_ID\n",
       "117    2831\n",
       "83     2212\n",
       "100    2052\n",
       "11     1983\n",
       "125    1949\n",
       "       ... \n",
       "116     191\n",
       "3       185\n",
       "65      119\n",
       "10       69\n",
       "77       10\n",
       "Name: count, Length: 152, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activity_log_df['User_ID'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94f5cf7c-9c15-4a2f-9cce-f09d22ab3abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User_ID\n",
       "117    3078\n",
       "83     2319\n",
       "100    2157\n",
       "11     2057\n",
       "125    2023\n",
       "       ... \n",
       "116     196\n",
       "3       186\n",
       "65      119\n",
       "10       73\n",
       "77       10\n",
       "Name: count, Length: 152, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_log_df['User_ID'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef7e59e-287c-4f6d-8d7c-b3ab76f9c39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge data\n",
    "merged_df = merge_data(activity_log_df, user_log_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b177015-d23e-4fd0-b115-e4b8ff7f8f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data\n",
    "pivot_df = reshape_data(merged_df)\n",
    "\n",
    "# Calculate statistics\n",
    "components = [\"Quiz\", \"Lecture\", \"Assignment\", \"Attendance\", \"Survey\"]\n",
    "stats = calculate_statistics(pivot_df, components)\n",
    "print(\"\\nStatistics:\")\n",
    "for component, stat in stats.items():\n",
    "    print(f\"{component}: {stat}\")\n",
    "\n",
    "# Plot correlation\n",
    "components_to_analyze = [\"Assignment\", \"Quiz\", \"Lecture\", \"Book\", \"Project\", \"Course\"]\n",
    "plot_correlation(pivot_df, components_to_analyze)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
